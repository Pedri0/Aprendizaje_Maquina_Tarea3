{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> Regresión logística vs clasificador bayesiano ingenuo </font>\n",
    "Compara los métodos de regresión logística y el clasificador bayesiano ingenuo en las siguientes\n",
    "tareas:\n",
    "\n",
    "Discute qué modelo seleccionarías y por qué. Todos los modelos deberán ser evaluados con 10\n",
    "repeticiones de validación cruzada estratificada de 5 particiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clasificación de spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5172 entries, 0 to 5171\n",
      "Columns: 2001 entries, 0 to Spam?\n",
      "dtypes: int64(2001)\n",
      "memory usage: 79.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>Spam?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  1991  1992  1993  1994  1995  1996  \\\n",
       "0     0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1     1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2     1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...     0     1     0     0     0     0   \n",
       "4     1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   ...   ...   ...   \n",
       "5167  0  0  0  0  0  0  0  0  4  0  ...     0     0     0     0     0     0   \n",
       "5168  0  0  0  0  3  4  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "5169  0  0  0  0  1  0  0  0  1  0  ...     0     0     0     0     0     0   \n",
       "5170  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "5171  0  0  0  0  4  0  0  0  4  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "      1997  1998  1999  Spam?  \n",
       "0        0     0     0      1  \n",
       "1        0     0     1      1  \n",
       "2        0     0     0      1  \n",
       "3        0     0     0      1  \n",
       "4        0     0     0      1  \n",
       "...    ...   ...   ...    ...  \n",
       "5167     0     0     0      0  \n",
       "5168     0     0     0      0  \n",
       "5169     0     0     0      0  \n",
       "5170     0     0     0      0  \n",
       "5171     0     0     0      0  \n",
       "\n",
       "[5172 rows x 2001 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos librerias utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Leemos nuestros datos\n",
    "spam = pd.read_csv('spam.csv',header=None,sep='\\s+')\n",
    "#Renombramos la ultima columna del dataframe\n",
    "spam.rename(columns={2000:'Spam?'}, inplace=True)\n",
    "#imprimimos la info del dataframe para ver si hay datos faltantes\n",
    "spam.info()\n",
    "#imprimimos las primeras 5 filas\n",
    "spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que todas las columnas son del tipo int64, por lo que suponemos que no hay datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "#buscamos si hay valores en cada fila de la columna Spam? un numero mayor que 1, ya que eso lo consideramos como un\n",
    "#error en los datos, ya que este df solo toma en cuenta 1 si el correo es spam o 0 si\n",
    "#no lo es. Para ello primero pasamos la calumna Spam? del df a una matriz numpy.\n",
    "spm = (spam['Spam?']).to_numpy()\n",
    "print(np.where(spm > 1))\n",
    "#vemos que es un array vacio por lo que consideramos que los datos estan limpios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar la validacion cruzada estratificada de 5 particiones debemos asegurarnos que las clases estan desbalanceadas, es decir la cantidad de correos spam y no spam no son iguales. Para ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 1500 correos Spam\n",
      "Hay 3672 correos que no son Spam\n"
     ]
    }
   ],
   "source": [
    "esSpam = np.where(spm == 1)\n",
    "print('Hay %d correos Spam'%esSpam[0].shape)\n",
    "noSpam = np.where(spm == 0)\n",
    "print('Hay %d correos que no son Spam'%noSpam[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particionesEstratificadas(particion,y,semilla):\n",
    "    #definimos un array ordenados_y que contendra los indices de y tales que y queda ordenada de menor a mayor\n",
    "    #por ejemplo si y es [4,3,2] ordenados_y sera [2,1,0] si lo interpretamos como los indices de y tal que y queda\n",
    "    #ordenada tenemos que [2,3,4]\n",
    "    ordenados_y = np.argsort(y)\n",
    "    #creamos un array no inicializado de la longitud de y\n",
    "    particiones = np.empty(len(y), dtype=np.int32)\n",
    "    \n",
    "    #Para reproducibilidad ajustamos la semilla\n",
    "    np.random.seed(semilla)\n",
    "    #iteramos desde cero hasta el tamaño de ordenados_y con paso \"particion\" (va a ser 5) definido por el usuario\n",
    "    for i in range(0, ordenados_y.shape[0], particion):\n",
    "        #define una nueva matriz particion_idx que contendra los valores de ordenados_y (indices de y) desde\n",
    "        #el paso i hasta i+particion\n",
    "        particion_idx = ordenados_y[i:i+particion]\n",
    "        #haz un suffle a los valordes de particion_idx\n",
    "        #np.random.shuffle(particion_idx)\n",
    "        #guarda en el array particiones en la posicion dada por los valores de particion_idx un arange hasta la longitud\n",
    "        #de particion_idx en el momento actual\n",
    "        particiones[particion_idx] = np.arange(len(particion_idx))\n",
    "                    \n",
    "    return particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, ..., 2, 3, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creamos las particiones estratificadas en el array particiones\n",
    "particiones = particionesEstratificadas(5,spm,42)\n",
    "particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    4,    9, ..., 5155, 5160, 5165], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definimos a como el array que contiene los indices de particiones tales que son igual a 1 (pertenecen a la\n",
    "#primera particion) (hay 5 del cero a l 4).\n",
    "a = np.where(particiones ==1)[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1035,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos el tamaño de spm en los indices recien calculados\n",
    "spm[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la particion 1 hay 300 correos spam\n",
      "En la particion 1 hay 735 correos no spam\n"
     ]
    }
   ],
   "source": [
    "#Imprimimos cuantos correos son spam de acuerdo a la particion 1\n",
    "print('En la particion 1 hay %d correos spam'%np.count_nonzero(spm[a] == 1))\n",
    "#Imprimimos cuantos correos son spam de acuerdo a la particion 1\n",
    "print('En la particion 1 hay %d correos no spam'%np.count_nonzero(spm[a] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la particion 0 hay 300 correos spam\n",
      "En la particion 0 hay 735 correos no spam\n",
      "En la particion 1 hay 300 correos spam\n",
      "En la particion 1 hay 735 correos no spam\n",
      "En la particion 2 hay 300 correos spam\n",
      "En la particion 2 hay 734 correos no spam\n",
      "En la particion 3 hay 300 correos spam\n",
      "En la particion 3 hay 734 correos no spam\n",
      "En la particion 4 hay 300 correos spam\n",
      "En la particion 4 hay 734 correos no spam\n"
     ]
    }
   ],
   "source": [
    "#Hagamos un ciclo for para comprobar todas las particiones\n",
    "for fold in range(5):\n",
    "    a = np.where(particiones == fold)[0]\n",
    "    #Imprimimos cuantos correos son spam de acuerdo a la particion fold\n",
    "    print('En la particion %d'  %fold + ' hay %d correos spam' %np.count_nonzero(spm[a] == 1))\n",
    "    #Imprimimos cuantos correos son spam de acuerdo a la particion 1\n",
    "    print('En la particion %d' %fold + ' hay %d correos no spam' %np.count_nonzero(spm[a] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que con la particion estratificada, las 5 particiones quedan balanceadas con respecto a las dos clases. Esto es, justo la definicion de k particiones estratificadas. Comprobemos que realmente el balance se hace correctamente, esta comprobacion se va a hacer con la funcion de Scikit-learn ya implementada y vamos a imprimir la cantidad de correos spam y no spam en las particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5172, 2000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definimos nuestras variables independientes\n",
    "X = (spam.drop(columns='Spam?')).to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=2937, 1=1200, Test: 0=735, 1=300\n",
      ">Train: 0=2937, 1=1200, Test: 0=735, 1=300\n",
      ">Train: 0=2938, 1=1200, Test: 0=734, 1=300\n",
      ">Train: 0=2938, 1=1200, Test: 0=734, 1=300\n",
      ">Train: 0=2938, 1=1200, Test: 0=734, 1=300\n"
     ]
    }
   ],
   "source": [
    "#importa la libreria StratifiedKfold de scikit, para hacer particiones estratificadas\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "#define 5 particiones con suffle activado y una semilla\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_ix, test_ix in kfold.split(X, spm):\n",
    "    # selescciona las filas para train y test\n",
    "    train_X, test_X = X[train_ix], X[test_ix]\n",
    "    train_y, test_y = spm[train_ix], spm[test_ix]\n",
    "    # cuenta las longitudes de train y test, divididas segun su clase\n",
    "    train_0, train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
    "    test_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1])\n",
    "    print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es bastante similar. Para el caso de Test los numeros coinciden para una sola particion y para train vemos que son cuatro particiones unidas. Por lo que debemos hacer que una vez pasada la funcion definir quien sera train y quien sera test. Esto se hace junto con la implementacion de las repeticiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacionEstratificada(x,y,repeticiones,particiones):\n",
    "    #iteramos sobre las repeticiones\n",
    "    for i in range(repeticiones):\n",
    "        #calculamos las particiones con semilla i para procurar que en cada iteracion la variable particion\n",
    "        #no sea igual a la anterior\n",
    "        particion = particionesEstratificadas(particiones,y,i)\n",
    "        #dado que debemos pegar 4 particiones para entrenamiento y 1 para validacion tenemos que itrerar\n",
    "        #sobre las cuatro particiones\n",
    "        for fold in range(particiones):\n",
    "            #Creamos una variable auxiliar (array) que nos va a elegir quienes seran para Train y quienes para test\n",
    "            z = np.arange(5)\n",
    "            #aplicamos un suffle a z\n",
    "            np.random.shuffle(z)\n",
    "            #creamos arrays auxiliares para evitar hacer el codigo ilegible, en estas arrays vamos a almacenar los\n",
    "            #indices del array particion tal que pertenecen a una particion determinada\n",
    "            uno = np.where(particion==z[0])\n",
    "            dos = np.where(particion==z[1])\n",
    "            tres = np.where(particion==z[2])\n",
    "            cuatro = np.where(particion==z[3])\n",
    "            cinco = np.where(particion==z[4])\n",
    "            #definimos el conjunto de train al pegar o concatenar a las 4 particiones, mientras que las\n",
    "            #de test sera unicamente el indice que no quedo dentro de los primeros folds del shuffle\n",
    "            xTrain = np.concatenate((x[uno],x[dos],x[tres],x[cuatro]),axis=0)\n",
    "            xTest = x[cinco]\n",
    "            yTrain = np.concatenate((y[uno],y[dos],y[tres],y[cuatro]),axis=0)\n",
    "            yTest = y[cinco]\n",
    "            #pegamos una columna de unos para calcular el parametro theta_0\n",
    "            unos = np.ones((xTrain.shape[0],1),dtype=float)\n",
    "            xTrain = np.append(unos,xTrain,axis=1)\n",
    "            unos = np.ones((xTest.shape[0],1),dtype=float)\n",
    "            xTest = np.append(unos,xTest,axis=1)\n",
    "            yield xTrain, yTrain, xTest, yTest        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar regresion logistica debemos usar descenso del gradiente. Para ello reutilizaremos el codigo escrito en la libreta Go.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos una funcion llamada sigmoide que no es exactamente la sigmoide original pero si la resta entre\n",
    "#el valor real y menos sigmoide(vector_theta_Transpuesto por vector_x) y nos va a regresar dicha resta\n",
    "def sigmoide(x,y,theta):\n",
    "    sigma = y - ((1)/(1+np.exp(-(theta.T@x))))\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos nuestra funcion de perdida que es el negativo de la verosimilitud logaritmica\n",
    "#definido en las slides de la clase, archivo 3a_regresion_clasificacion_lineal.pdf slide 43\n",
    "#esta funcion nos regresa un valor de error\n",
    "def loss(x,y,theta):\n",
    "    error = (y*np.log((1/(1+np.exp(-(theta.T@x))))))+((1-y)*np.log(1-((1/(1+np.exp(-(theta.T@x)))))))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos nuestra funcion de entrenamiento para determinar el vector de Theta que minimiza el error\n",
    "#con ayuda del descenso del gradiente. Esta funcion come vectores x, vectores y e un entero iteraciones\n",
    "def entrena(x,y,iteraciones):\n",
    "    #definimos una lista que contendra los errores para cada iteracion (distintos valores de theta)\n",
    "    historicoLoss = []\n",
    "    #definimos nuestro vector de Thetas (theta_0,theta_1,theta_2) todos se inicializan en cero\n",
    "    theta = np.zeros((2001,1),dtype=np.float32)\n",
    "    #iteramos sobre las iteraciones definidas por el usuario\n",
    "    for pasos in range(iteraciones):\n",
    "        #Reseteamos/seteamos el gradiente como un vector de ceros (cada entrada sera el gradiente para cada variable)\n",
    "        gradiente = np.zeros((2001,1),dtype=np.float32)\n",
    "        #Reseteamos/seteamos la perdida para cada iteracion en las filas de x en cero\n",
    "        perdidaiter = 0\n",
    "        #para cada fila del vector de entrada x\n",
    "        for u in range(x.shape[0]):\n",
    "            #para cada fila del vector theta\n",
    "            for r in range(theta.shape[0]):\n",
    "                #para una fila dada de theta, suma iterativamente el gradiente + x en la fila u, columna r\n",
    "                #por la funcion sigmoide que definimos antes con entradas el vector x en la fila, el valor\n",
    "                #real y en la fila u y el parametro theta\n",
    "                #Todo esto es la definicion del gradiente o derivada de la funcion error\n",
    "                gradiente[r] = gradiente[r] + x[u][r]*sigmoide(x[u],y[u],theta)\n",
    "            #una vez que terminas de calcular el gradiente en una fila dada, suma iterativamente\n",
    "            #la perdida en cada iteracion hasta terminar las filas de x\n",
    "            perdidaiter += loss(x[u],y[u],theta)\n",
    "        #una vez que termines de calcular el gradiente y la perdida de cada fila, actualiza el valor del vector\n",
    "        #theta haciendo uso de el paso definido como 0.01 y el gradiente calculado, repite con este nuevo vector\n",
    "        #theta hasta acabar las iteraciones\n",
    "        theta += 0.01*gradiente\n",
    "        #en la lista de perdidas agrega la perdida que calculaste\n",
    "        historicoLoss.append(-1*perdidaiter[0])\n",
    "    #regresa el ultimo valor de theta y la lista de perdidas\n",
    "    return theta,historicoLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la funcion sigmoide original y la llamamos predice\n",
    "def predice(x,theta):\n",
    "    #funcion sigmoide original calculada con los vectores de entrada theta y x\n",
    "    sigma = ((1)/(1+np.exp(-(theta.T@x))))\n",
    "    #regresa el valor de sigma\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta = np.zeros((2000,1), dtype=float)\n",
    "Loss = np.zeros((50,800),dtype=float)\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-fe3d99cb73de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalidacionEstratificada\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mTheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLoss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mentrena\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-1293a715f3c0>\u001b[0m in \u001b[0;36mentrena\u001b[1;34m(x, y, iteraciones)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;31m#real y en la fila u y el parametro theta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;31m#Todo esto es la definicion del gradiente o derivada de la funcion error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mgradiente\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradiente\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigmoide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;31m#una vez que terminas de calcular el gradiente en una fila dada, suma iterativamente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m#la perdida en cada iteracion hasta terminar las filas de x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-9ec2ea191e68>\u001b[0m in \u001b[0;36msigmoide\u001b[1;34m(x, y, theta)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#el valor real y menos sigmoide(vector_theta_Transpuesto por vector_x) y nos va a regresar dicha resta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for xTrain, yTrain, xTest, yTest in validacionEstratificada(X, spm,2,2):\n",
    "    Theta[i],Loss[i] =  entrena(xTrain,yTrain,50)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y_true, alpha=0.01, steps=50):\n",
    "    # ejemplos, atributos\n",
    "    m, n = x.shape\n",
    "    # inicialización de parámetros\n",
    "    Theta = np.random.normal(0, 1, n)\n",
    "    # histórico de pérdidas\n",
    "    loss_hist = []\n",
    "    # ciclio de entrenamiento\n",
    "    for i in range(steps):\n",
    "        # computo de la hipótesis\n",
    "        y_pred = ((1)/(1+np.exp(-(Theta.T@x.T))))\n",
    "        # computo de la pérdida\n",
    "        loss = np.sum((-y_true.T*np.log(y_pred) - (1-y_true)*np.log((1-y_pred)))) / (m)\n",
    "        # computo del gradiente\n",
    "        grad = (x.T @ ((((1)/(1+np.exp(-(x@Theta)))) - y_true))) / m\n",
    "        # actualización de parámetros\n",
    "        Theta = Theta - alpha * grad\n",
    "        # histórico de pérdida\n",
    "        loss_hist.append(loss)\n",
    "    return Theta, loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reescalado(X):\n",
    "    xReg=np.zeros((X.shape[0],X.shape[1]),dtype=float)\n",
    "    for i in range(X.shape[1]):\n",
    "        maximo = np.amax(X[:,i])\n",
    "        minimo = np.amin(X[:,i])\n",
    "        for j in range (X.shape[0]):\n",
    "            xReg[j,i] = (X[j,i]-minimo)/(maximo-minimo)\n",
    "    return xReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Estandarizacion(x):\n",
    "    xReg=np.zeros((X.shape[0],X.shape[1]),dtype=float)\n",
    "    for i in range(X.shape[1]):\n",
    "        media = np.mean(X[:,i])\n",
    "        desviacion = np.std(X[:,i])\n",
    "        for j in range (X.shape[0]):\n",
    "            xReg[j,i] = (X[j,i]-media)/(desviacion)\n",
    "    return xReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "xReescalado = Reescalado(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thetha = np.zeros((50,2001),dtype=float)\n",
    "Lossi = np.zeros((50,50),dtype=float)\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xTrain, yTrain, xTest, yTest in validacionEstratificada(xReescalado, spm,10,5):\n",
    "    Thetha[i],Lossi[i] =  train(xTrain,yTrain)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7946838 ,  2.24110849,  1.86763735, ..., -1.5328873 ,\n",
       "        -1.71140907,  0.04631729],\n",
       "       [-0.96355442, -0.07999602, -0.7037211 , ...,  1.84394926,\n",
       "         0.27148511,  1.13665831],\n",
       "       [-1.28804495,  1.33931483,  1.28748182, ..., -0.01297721,\n",
       "         0.08395298, -0.05659989],\n",
       "       ...,\n",
       "       [ 1.6569366 , -0.94001309,  0.64061652, ..., -1.08684371,\n",
       "         2.2044682 , -0.22494648],\n",
       "       [-0.43330761, -2.02780266,  0.06432138, ..., -0.81528087,\n",
       "        -1.12684031,  1.10269541],\n",
       "       [-0.77731457, -0.225553  ,  0.46327803, ..., -0.02633685,\n",
       "         1.08864975,  0.44222022]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Thetha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
